# Database Configuration
POSTGRES_DB=mnemosyne
POSTGRES_USER=postgres

# Specify your PostgreSQL password here
# POSTGRES_PASSWORD=

# Specify an API key for Qdrant Configuration (optional for local dev)
# QDRANT_API_KEY=your_qdrant_api_key_here

# Django Configuration
## Specify your Django secret key here
# SECRET_KEY=
DEBUG=1
ALLOWED_HOSTS=localhost,127.0.0.1

# ============================================================================
# Phase 1: Embeddings Configuration (REQUIRED)
# ============================================================================
# Phase 1 only uses embeddings - no LLM extraction yet
# Choose one of the following providers:

# Option 1: Ollama (recommended for local/homeserver deployment)
EMBEDDINGS_PROVIDER=ollama
EMBEDDINGS_ENDPOINT_URL=http://host.docker.internal:11434
EMBEDDINGS_MODEL=mxbai-embed-large
# EMBEDDINGS_API_KEY=  # Not needed for Ollama
EMBEDDINGS_TIMEOUT=30

# Option 2: OpenAI
# EMBEDDINGS_PROVIDER=openai
# EMBEDDINGS_ENDPOINT_URL=https://api.openai.com/v1
# EMBEDDINGS_MODEL=text-embedding-3-small
# EMBEDDINGS_API_KEY=your_openai_api_key_here
# EMBEDDINGS_TIMEOUT=30

# Option 3: OpenAI-compatible (e.g., LM Studio, vLLM, etc.)
# EMBEDDINGS_PROVIDER=openai_compatible
# EMBEDDINGS_ENDPOINT_URL=http://your-server:port/v1
# EMBEDDINGS_MODEL=your-model-name
# EMBEDDINGS_API_KEY=your_api_key_if_needed
# EMBEDDINGS_TIMEOUT=30

# ============================================================================
# Legacy Configuration (Phase 0 - deprecated)
# ============================================================================
# These settings are no longer used in Phase 1
# OLLAMA_BASE_URL=http://localhost:11434
# RATE_LIMIT_EXTRACT_PER_MINUTE=20
# RATE_LIMIT_RETRIEVE_PER_MINUTE=60

# Security Configuration (optional)
# Generate API keys with: python manage.py generate_api_key
# Comma-separated list of valid API keys for additional protection
# MNEMOSYNE_API_KEYS=your_generated_key_here,another_key_if_needed